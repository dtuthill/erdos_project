{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7858dc71-3d04-41e6-8fc6-b920c08adb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def logic_win(x,x_r):\n",
    "    return (x >= x_r[0]) & (x < x_r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff97add-edc7-4c2d-808e-c4648debdb05",
   "metadata": {},
   "source": [
    "#### Import and clean dataset, select out London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345200f5-0823-4d30-a32d-a9610a5291ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/UK/combined_collisions.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c5d6396-021d-4646-b754-cc0207684d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time column has some nans in it, must drop those entries\n",
    "\n",
    "def is_str(x):\n",
    "    Nx = len(x)\n",
    "    I = np.ones(Nx).astype(bool)\n",
    "    for ii in range(Nx):\n",
    "        if type(x[ii]) != str:\n",
    "            I[ii] = False\n",
    "    return I\n",
    "\n",
    "df = df.loc[is_str(df.Time.values),:]\n",
    "df.aadf_Count_point_id = df.aadf_Count_point_id.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35cdc535-8eb3-4320-ac52-c07805240b65",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m get_ymd(df\u001b[38;5;241m.\u001b[39mDate\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     33\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_hour(df\u001b[38;5;241m.\u001b[39mTime\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m---> 34\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maadf_Year\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mreformat_aadf_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maadf_Year\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mreformat_aadf_year\u001b[1;34m(Year)\u001b[0m\n\u001b[0;32m     27\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(Ny)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Ny):\n\u001b[1;32m---> 29\u001b[0m     y[ii] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mYear\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "#make hour, year and month columns\n",
    "    #hour will be rounded \n",
    "def get_hour(T):\n",
    "    Nt = len(T)\n",
    "    H = np.zeros(Nt).astype(int)\n",
    "    for ii in range(Nt):\n",
    "        s = T[ii].split(':')\n",
    "        h = int(s[0])\n",
    "        m = int(s[1])\n",
    "        if m > 30:\n",
    "            h += 1\n",
    "        H[ii] = h % 24\n",
    "    return H\n",
    "\n",
    "def get_ymd(D):\n",
    "    Nd = len(D)\n",
    "    # |\n",
    "    ymd = np.zeros((Nd,3)).astype(int)\n",
    "    for ii in range(Nd):\n",
    "        s = D[ii].split('-')\n",
    "        for nn in range(3):\n",
    "            ymd[ii,nn] = int(s[nn])\n",
    "    return ymd\n",
    "\n",
    "def reformat_aadf_year(Year):\n",
    "    Ny = len(Year)\n",
    "    y = np.zeros(Ny).astype(int)\n",
    "    for ii in range(Ny):\n",
    "        y[ii] = int(Year[ii].split('-')[0])\n",
    "    return y\n",
    "\n",
    "df[['y','m','d']] = get_ymd(df.Date.values)\n",
    "df['h'] = get_hour(df.Time.values)\n",
    "df['aadf_Year'] = reformat_aadf_year(df.aadf_Year.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c46acee-e167-4daa-bf04-4b9dd0cf092d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(Ny)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Ny):\n\u001b[1;32m----> 5\u001b[0m     y[ii] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mYear\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "Year = df.aadf_Year.values\n",
    "Ny = len(Year)\n",
    "y = np.zeros(Ny).astype(int)\n",
    "for ii in range(Ny):\n",
    "    y[ii] = int(Year[ii].split('-')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f919ff97-825c-4577-a8cf-94c8701f8046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230598    2017-01-01 00:00:00\n",
       "85767     2010-01-01 00:00:00\n",
       "204133                    NaN\n",
       "35673     2007-01-01 00:00:00\n",
       "14114                     NaN\n",
       "235090    2018-01-01 00:00:00\n",
       "152053                    NaN\n",
       "15608                     NaN\n",
       "209769                    NaN\n",
       "240038                    NaN\n",
       "8469                      NaN\n",
       "122926    2012-01-01 00:00:00\n",
       "75377                     NaN\n",
       "225427                    NaN\n",
       "2392      2005-01-01 00:00:00\n",
       "90786                     NaN\n",
       "182481    2015-01-01 00:00:00\n",
       "210048                    NaN\n",
       "84068     2010-01-01 00:00:00\n",
       "215672                    NaN\n",
       "Name: aadf_Year, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.aadf_Year.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9dc537-b834-4eb0-8c0e-47918c293a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#central London box\n",
    "Lat_r = [51.475,51.543]\n",
    "Lon_r = [-0.179,0.023]\n",
    "\n",
    "I_lat = (df.Latitude > Lat_r[0]) & (df.Latitude < Lat_r[1])\n",
    "I_lon = (df.Longitude > Lon_r[0]) & (df.Longitude < Lon_r[1])\n",
    "I = I_lat & I_lon\n",
    "\n",
    "df_lond = df.loc[I,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "630aa8d0-7159-422b-934c-a22809b0de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all data that don't have traffic matches\n",
    "\n",
    "I = df_lond.match == True\n",
    "df_lond = df_lond.loc[I,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a9a945-1516-4b78-8a43-516e48946329",
   "metadata": {},
   "source": [
    "#### Make neighborhoods feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02eb5b9-1b57-45e2-be8f-a604000733b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a 3 (Lat, N/S) x 6 (Lon, E/W) grid\n",
    "Nlat = 3\n",
    "Nlon = 6\n",
    "Nneigh = Nlon*Nlat\n",
    "\n",
    "edges_lat = np.linspace(*Lat_r,Nlat+1)\n",
    "dlat = np.diff(edges_lat)[0]\n",
    "bins_lat = edges_lat[:-1]+0.5*dlat\n",
    "edges_lon = np.linspace(*Lon_r,Nlon+1)\n",
    "dlon = np.diff(edges_lon)[0]\n",
    "bins_lon = edges_lon[:-1]+0.5*dlon\n",
    "\n",
    "coord_neigh = [None]*Nneigh\n",
    "\n",
    "df_lond['neigh'] = 0 #initialize neighborhood feature\n",
    "ir = 0 #these are lat bins (rows)\n",
    "ic = 0 #lon bins\n",
    "for ii in range(Nneigh):\n",
    "    Ilat = logic_win(df_lond.Latitude,(edges_lat[ir],edges_lat[ir+1]))\n",
    "    Ilon = logic_win(df_lond.Longitude,(edges_lon[ic],edges_lon[ic+1]))\n",
    "    I = Ilat & Ilon\n",
    "    df_lond.loc[I,'neigh'] = ii\n",
    "    \n",
    "    coord_neigh[ii] = np.array([bins_lat[ir],bins_lon[ic]])\n",
    "    \n",
    "    ic+=1\n",
    "    if ic == Nlon:\n",
    "        ic = 0\n",
    "        ir+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18c2fa-5da9-4eb2-a3c8-d46dd51bbb46",
   "metadata": {},
   "source": [
    "#### Make a DataFrame using df_lond that has entries only for traffic IDs. Main feature is # of incidents.Â¶\n",
    "- Other features are the aadf features that go along with the ID\n",
    "- Also maybe some averaged features from accidents dataset (like junction control, maybe just use the classification with the most entries for that ID)\n",
    "- Maybe the target variable should be number of incidents normalized by the bike volume (this is prob. of an incident)\n",
    "\n",
    "##### Features to include\n",
    "- all aadf features (do they neeed to be averaged over year? Maybe just average anyway)\n",
    "- modes of classification features in accidents\n",
    "- num. of incidents\n",
    "- num. of serious and fatal incidents\n",
    "- num. of incidents normalized to bike volume from aadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec11dbf9-51fb-44e4-9b69-98f61eaac58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01 00:00:00    19\n",
       "2013-01-01 00:00:00    14\n",
       "2008-01-01 00:00:00    13\n",
       "2012-01-01 00:00:00    13\n",
       "2017-01-01 00:00:00    13\n",
       "2006-01-01 00:00:00    12\n",
       "2010-01-01 00:00:00    12\n",
       "2011-01-01 00:00:00    11\n",
       "2007-01-01 00:00:00    10\n",
       "2015-01-01 00:00:00     9\n",
       "2016-01-01 00:00:00     9\n",
       "2018-01-01 00:00:00     9\n",
       "2009-01-01 00:00:00     8\n",
       "2005-01-01 00:00:00     7\n",
       "Name: aadf_Year, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = traf_IDs[3]\n",
    "I = df_lond.aadf_Count_point_id == ID\n",
    "df_lond.loc[I,'aadf_Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05045aa-162c-48e9-a675-fc52a9113c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "traf_IDs = np.array(df_lond.aadf_Count_point_id.value_counts().index)\n",
    "Ninc_IDs = np.array(df_lond.aadf_Count_point_id.value_counts().values)\n",
    "\n",
    "I = Ninc_IDs > 10 #this will select roads to include in the new DataFrame based on if they had at least this many accidents\n",
    "I.sum()\n",
    "\n",
    "IDs_df = traf_IDs[I]\n",
    "Nid = len(IDs_df)\n",
    "\n",
    "df_road = pd.DataFrame({'aadfID':IDs_df})\n",
    "slight_rd = np.zeros(Nid).astype(int)\n",
    "ser_rd = np.zeros(Nid).astype(int)\n",
    "total_rd = np.zeros(Nid).astype(int)\n",
    "for nn,ii in enumerate(IDs_df):\n",
    "    I = df_lond.aadf_Count_point_id.values == ii\n",
    "    total_rd[nn] = I.sum()\n",
    "    slight_rd[nn] = df_lond.loc[I,'slight'].values.sum()\n",
    "    ser_rd[nn] = total_rd[nn] - slight_rd[nn]\n",
    "df_road['total'] = total_rd\n",
    "df_road['slight'] = slight_rd\n",
    "df_road['serious'] = ser_rd\n",
    "\n",
    "safety_mode = ['neigh','Road_name','Road_name2','h','Day_of_Week','m','Speed_limit','Junction_Detail','Junction_Control','Pedestrian_Crossing-Physical_Facilities']\n",
    "aadf_av = ['aadf_Pedal_cycles','aadf_Pedal_cycles','aadf_All_motor_vehicles','aadf_All_HGVs','aadf_LGVs','aadf_Buses_and_coaches']\n",
    "aadf_mode = ['aadf_Road_name','aadf_Road_category','aadf_Road_type']\n",
    "for f in safety_mode:\n",
    "    df_road[f] = np.zeros(Nid).astype(int)\n",
    "    for nn,ii in enumerate(IDs_df):\n",
    "        I = df_lond.aadf_Count_point_id.values == ii\n",
    "        df_road.loc[nn,f] = df_lond.loc[I,f].mode().values[0]\n",
    "\n",
    "for f in aadf_mode:\n",
    "    df_road[f] = np.zeros(Nid).astype(int)\n",
    "    for nn,ii in enumerate(IDs_df):\n",
    "        I = df_lond.aadf_Count_point_id.values == ii\n",
    "        df_road.loc[nn,f] = df_lond.loc[I,f].mode().values[0]\n",
    "        \n",
    "for f in aadf_av:\n",
    "    df_road[f] = np.zeros(Nid).astype(int)\n",
    "    for nn,ii in enumerate(IDs_df):\n",
    "        I = df_lond.aadf_Count_point_id.values == ii\n",
    "        df_road.loc[nn,f] = df_lond.loc[I,f].mean()\n",
    "        \n",
    "df_road['total_norm'] = df_road['total'].values/df_road['aadf_Pedal_cycles'].values\n",
    "df_road['serious_ratio'] = df_road['serious'].values/df_road['total'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae32d0f-ccd8-4105-9206-c3fbcc7ea5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
